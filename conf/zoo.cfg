# The number of milliseconds of each tick
#Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。tickTime以毫秒为单位。
tickTime=2000
# The number of ticks that the initial 
# synchronization phase can take
#集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量）
initLimit=10
# The number of ticks that can pass between 
# sending a request and getting an acknowledgement
#集群中的follower服务器与leader服务器之间请求和应答之间能容忍的最多心跳数（tickTime的数量）
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just 
# example sakes.
#Zookeeper保存数据的目录，默认情况下，Zookeeper将写数据的日志文件也保存在这个目录里
dataDir=C:\data_dir\zookeeper
# the port at which the clients will connect
#客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求
clientPort=2181
# the maximum number of client connections.
# increase this if you need to handle more clients
#maxClientCnxns=60
#
# Be sure to read the maintenance section of the 
# administrator guide before turning on autopurge.
#
# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance
#
# The number of snapshots to retain in dataDir
#autopurge.snapRetainCount=3
# Purge task interval in hours
# Set to "0" to disable auto purge feature
#autopurge.purgeInterval=1

## Metrics Providers
#
# https://prometheus.io Metrics Exporter
#metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider
#metricsProvider.httpPort=7000
#metricsProvider.exportJvmInfo=true

#6.服务器名称与地址：集群信息（服务器编号，服务器地址，LF通信端口，选举端口）
#这个配置项的书写格式比较特殊，规则如下：
#server.N=YYY:A:B
#
#server.1=itcast05:2888:3888
#server.2=itcast06:2888:3888
#server.3=itcast07:2888:3888
#
#7.ZK为什么设置为奇数个？
#zookeeper有这样一个特性：集群中只要有过半的机器是正常工作的，那么整个集群对外就是可用的。也就是说如果有2个zookeeper，那么只要有1个死了zookeeper就不能用了，因为1没有过半，所以2个zookeeper的死亡容忍度为0；同理，要是有3个zookeeper，一个死了，还剩下2个正常的，过半了，所以3个zookeeper的容忍度为1；同理你多列举几个：2 -> 0; 3 -> 1; 4 - >1; 5 -> 2; 6 -> 2会发现一个规律，2n和2n-1的容忍度是一样的，都是n-1，所以为了更加高效，何必增加那一个不必要的zookeeper呢。
#
#8.ZK集群安装
#
#复制代码
#1.上传zk安装包
#
#2.解压
#
#3.配置（先在一台节点上配置）
#    3.1将文件/conf/zoo_sample.cfg改为/conf/zoo.cfg
#        mv zoo_sample.cfg zoo.cfg
#
#    3.2修改配置文件（zoo.cfg）
#        dataDir=/hadoop/zookeeper-3.4.5/tmp
#
#        server.1=hadoop04:2888:3888
#        server.2=hadoop05:2888:3888
#        server.3=hadoop06:2888:3888
#
#    3.3在（dataDir=/hadoop/zookeeper-3.4.5/tmp）创建一个myid文件，里面内容是server.N中的N（server.2里面内容为2）
#        echo "1" > myid
#
#    3.4将配置好的zk拷贝到其他节点
#        scp -r /hadoop/zookeeper-3.4.5/ hadoop05:/hadoop/
#        scp -r /hadoop/zookeeper-3.4.5/ hadoop06:/hadoop/
#
#    3.5注意：在其他节点上一定要修改myid的内容
#        在hadoop05应该讲myid的内容改为2 （echo "2" > myid）
#        在hadoop06应该讲myid的内容改为3 （echo "3" > myid）
#
#4.启动集群
#    分别启动zk
#        ./zkServer.sh start

